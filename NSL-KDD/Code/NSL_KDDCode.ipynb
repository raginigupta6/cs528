{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "NSL_KDDCode.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LvirvNaV1gT3"
      ],
      "toc_visible": true,
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZixxRgn_QE2"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9hIv2s7_QE6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "d52404ba-ecf1-4150-c817-7fbd9a8e7dce"
      },
      "source": [
        "%config IPCompleter.greedy=True\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import re\n",
        "import sklearn\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib as matplot\n",
        "%matplotlib inline\n",
        "\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras import regularizers\n",
        "\n",
        "from sklearn.metrics import (confusion_matrix, precision_recall_curve, auc,\n",
        "                             roc_curve, recall_score, classification_report, f1_score,\n",
        "                             precision_recall_fscore_support)\n",
        "\n",
        "from sklearn import linear_model\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder,normalize"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcmNZAzs_Svh"
      },
      "source": [
        "labels = ['duration', 'protocol_type', 'service', 'flag', 'src_bytes',\n",
        "'dst_bytes', 'land', 'wrong_fragment', 'urgent', 'hot',\n",
        "'num_failed_logins', 'logged_in', 'num_compromised', 'root_shell',\n",
        "'su_attempted', 'num_root', 'num_file_creations', 'num_shells',\n",
        "'num_access_files', 'num_outbound_cmds', 'is_host_login',\n",
        "'is_guest_login', 'count', 'srv_count', 'serror_rate',\n",
        "'srv_serror_rate', 'rerror_rate', 'srv_rerror_rate', 'same_srv_rate',\n",
        "'diff_srv_rate', 'srv_diff_host_rate', 'dst_host_count',\n",
        "'dst_host_srv_count', 'dst_host_same_srv_rate', 'dst_host_diff_srv_rate', 'dst_host_same_src_port_rate',\n",
        "'dst_host_srv_diff_host_rate', 'dst_host_serror_rate',\n",
        "'dst_host_srv_serror_rate', 'dst_host_rerror_rate',\n",
        "'dst_host_srv_rerror_rate', 'attack_type', 'difficulty_level']# subclass - > attack_type\n",
        "\n",
        "train = pd.read_csv('https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTrain%2B.csv')\n",
        "test = pd.read_csv('https://raw.githubusercontent.com/defcom17/NSL_KDD/master/KDDTest%2B.csv')\n",
        "train.columns , test.columns = labels , labels\n",
        "combined_data = pd.concat([train, test]).drop('difficulty_level', 1)\n",
        "# combined_data.shape\n",
        "# combined_data.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xbsr_Auy_QFN"
      },
      "source": [
        "### The following few cells are taken from the 'sample code'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nl9Yok3f_QFO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201
        },
        "outputId": "8f6b613b-2ea5-4811-d782-3e533a65bf72"
      },
      "source": [
        "le = LabelEncoder()\n",
        "\n",
        "vector = combined_data['attack_type']\n",
        "\n",
        "print(\"Attack Vectors:\", set(list(vector))) # use print to make it print on single line \n",
        "combined_data['attack_type'] = le.fit_transform(vector)\n",
        "combined_data['protocol_type'] = le.fit_transform(combined_data['protocol_type'])\n",
        "combined_data['service'] = le.fit_transform(combined_data['service'])\n",
        "combined_data['flag'] = le.fit_transform(combined_data['flag'])\n",
        "\n",
        "print('\\nDescribing attack_type: ')\n",
        "print(\"min\", vector.min())\n",
        "print(\"max\", vector.max())\n",
        "print(\"mode\",vector.mode())\n",
        "print(\"mode\", len(np.where(vector.values==16)[0])/len(vector),\"%\")\n",
        "print(\"looks like 16 is 'normal' \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Attack Vectors: {'mscan', 'imap', 'apache2', 'saint', 'guess_passwd', 'ipsweep', 'normal', 'spy', 'teardrop', 'back', 'mailbomb', 'loadmodule', 'snmpgetattack', 'land', 'worm', 'perl', 'warezclient', 'ftp_write', 'udpstorm', 'portsweep', 'named', 'warezmaster', 'nmap', 'pod', 'rootkit', 'sqlattack', 'xlock', 'neptune', 'multihop', 'httptunnel', 'buffer_overflow', 'xterm', 'ps', 'snmpguess', 'sendmail', 'xsnoop', 'satan', 'phf', 'processtable', 'smurf'}\n",
            "\n",
            "Describing attack_type: \n",
            "min apache2\n",
            "max xterm\n",
            "mode 0    normal\n",
            "dtype: object\n",
            "mode 0.0 %\n",
            "looks like 16 is 'normal' \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LvirvNaV1gT3"
      },
      "source": [
        "# Reduce feature space - unused"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMafgVi9ZLEA"
      },
      "source": [
        "def RFS(): \n",
        "  # select least correlated\n",
        "  corr_matrix = combined_data.corr().abs().sort_values('attack_type')\n",
        "  # tmp.head(10) # to view CORR matrix \n",
        "  leastCorrelated = corr_matrix['attack_type'].where(lambda x: x < 0.005).dropna()\n",
        "  leastCorrelated = list(leastCorrelated.index)\n",
        "\n",
        "  # select least STD\n",
        "  leastSTD = combined_data.std().to_frame().where(lambda x: x < 0.05).dropna()#.nsmallest(20, columns=0)\n",
        "  leastSTD = list(leastSTD.transpose().columns)\n",
        "\n",
        "  featureElimination = set(leastCorrelated + leastSTD)\n",
        "  return featureElimination\n",
        "\n",
        "# featureElimination = RFS()\n",
        "# len(featureElimination)\n",
        "# featureElimination\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60WOhD9X_QFf"
      },
      "source": [
        "# Drop features and perform train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4xaj5Z0ZURo"
      },
      "source": [
        "# combined_data_reduced = combined_data.drop(featureElimination,axis=1)\n",
        "\n",
        "data_x = combined_data.drop('attack_type', axis=1)\n",
        "data_y = combined_data.loc[:,['attack_type']]\n",
        "# del combined_data # free mem\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_x, data_y, test_size=.5, random_state=42) # TODO\n",
        "\n",
        "X_train = pd.DataFrame(normalize(X_train))\n",
        "X_test = pd.DataFrame(normalize(X_test)) # this is worng (cheating), i should have used a sk-learn obj. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyXt8Id41wlr"
      },
      "source": [
        "# Basline ML "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4e7NTqd_QFr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "68d27f39-0e5b-43e3-f3f1-246980a2e329"
      },
      "source": [
        "import gc \n",
        "_ = gc.collect()\n",
        "print(\"# of Dims, \",X_train.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "# of Dims,  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPbIkY3GNXp6"
      },
      "source": [
        "DTC = DecisionTreeClassifier() \n",
        "RFC = RandomForestClassifier(n_estimators=25, random_state=1)\n",
        "ETC = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\n",
        "x = X_train\n",
        "y = y_train['attack_type'].ravel()\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', DTC), ('rf', RFC),('et',ETC)], voting='hard') \n",
        "for clf, label in zip([DTC, RFC,ETC, eclf], ['DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'Ensemble']): \n",
        "    _ = clf.fit(x,y)\n",
        "    pred = clf.score(X_test,y_test)\n",
        "    print(\"Acc: %0.10f [%s]\" % (pred,label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_Zp-BxRqwWI"
      },
      "source": [
        "# Comparison"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wn77ZwlBHcbA"
      },
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.decomposition import PCA,TruncatedSVD\n",
        "from sklearn.svm import LinearSVC\n",
        "n = 30 "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-iOXHZnhHkgA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "fe761d31-d2e2-47c8-8df5-0b74397b9cf0"
      },
      "source": [
        "rfe = RFE(DTC, n).fit(x,y)\n",
        "\n",
        "desiredIndices = np.where(rfe.support_==True)[0]\n",
        "whitelist = X_train.columns.values[desiredIndices]\n",
        "X_train_RFE,X_test_RFE = X_train[whitelist],X_test[whitelist]\n",
        "\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('DecisionTreeClassifier', DTC), ('RandomForestClassifier', RFC),('ExtraTreesClassifier',ETC)], voting='hard')\n",
        "_ = eclf.fit(X_train_RFE,y_train)\n",
        "pred = eclf.score(X_test_RFE,y_test)\n",
        "\n",
        "print(\"Acc: %0.10f\" % (pred))\n",
        "print(\"number of features\",X_train_RFE.shape[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Acc: 0.9931723609\n",
            "number of features 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de-bqkRqL5R4"
      },
      "source": [
        "The above cell shows the tradeoff of garbagings the least useful features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9RcHtOGHkie",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c6bdecd7-b35b-4be2-9b84-7c4fedbae486"
      },
      "source": [
        "svd = TruncatedSVD(n_components=n-20) \n",
        "_ = svd.fit(X_train_RFE)  \n",
        "\n",
        "X_train_svd, X_test_svd = svd.transform(X_train_RFE), svd.transform(X_test_RFE)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('DecisionTreeClassifier', DTC), ('RandomForestClassifier', RFC),('ExtraTreesClassifier',ETC)], voting='hard')\n",
        "_ = eclf.fit(X_train_svd,y_train)\n",
        "\n",
        "pred = eclf.score(X_test_svd,y_test)\n",
        "print(\"Acc: %0.10f\" % (pred))\n",
        "print(\"number of features\",X_train_svd.shape[1])\n",
        "\n",
        "print(len(svd.components_) , \"components,\",len(svd.components_[0]), \" length\")\n",
        "\n",
        "'''\n",
        "Acc: 0.9921219548\n",
        "number of features 20\n",
        "----\n",
        "Acc: 0.9851461815\n",
        "number of features 10\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nAcc: 0.9921219548\\nnumber of features 20\\n----\\nAcc: 0.9851461815\\nnumber of features 10\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3gqhZeCCQRS"
      },
      "source": [
        "# Benchmark post feature reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KozdNU1ZCL25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "ca9a917b-27fa-4437-bc12-1b9e5546cf27"
      },
      "source": [
        "print(X_train_svd.shape)\n",
        "\n",
        "DTC = DecisionTreeClassifier() \n",
        "RFC = RandomForestClassifier(n_estimators=25, random_state=1)\n",
        "ETC = ExtraTreesClassifier(n_estimators=10, criterion='gini', max_features='auto', bootstrap=False)\n",
        "\n",
        "eclf = VotingClassifier(estimators=[('lr', DTC), ('rf', RFC),('et',ETC)], voting='hard') \n",
        "for clf, label in zip([DTC, RFC,ETC, eclf], ['DecisionTreeClassifier', 'RandomForestClassifier', 'ExtraTreesClassifier', 'Ensemble']): \n",
        "    _ = eclf.fit(X_train_svd,y_train)\n",
        "    pred = eclf.score(X_test_svd,y_test)\n",
        "    print(\"Acc: %0.10f [%s]\" % (pred,label))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(74257, 10)\n",
            "Acc: 0.9861427206 [DecisionTreeClassifier]\n",
            "Acc: 0.9858464522 [RandomForestClassifier]\n",
            "Acc: 0.9860349866 [ExtraTreesClassifier]\n",
            "Acc: 0.9862100543 [Ensemble]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwrnZAAmMDxd"
      },
      "source": [
        "0.985 for 10 dimensions of data\n",
        "\n",
        "I like this better than 0.9937110306 with 41 features (dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PBGhBr07Mi7q"
      },
      "source": [
        "# Auto Encoder - not working "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHzCcKw-LhhQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ee49a940-36f9-415f-de6a-212038a799ab"
      },
      "source": [
        "gc.collect()\n",
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "# print(X_train_RFE.shape)\n",
        "# print(X_test_RFE.shape)\n",
        "# print(X_train_svd.shape) \n",
        "# print(X_test_svd.shape)\n",
        "\n",
        "from sklearn.preprocessing import minmax_scale # 0.59 \n",
        "from sklearn.preprocessing import StandardScaler # much beter "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "144"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        },
        {
          "output_type": "stream",
          "text": [
            "(74257, 41)\n",
            "(74257, 41)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1Tk03USgHJj"
      },
      "source": [
        "data_xx = data_x.copy()\n",
        "data_xx = StandardScaler().fit_transform(data_xx)\n",
        "X_train, X_test, y_train, y_test = train_test_split(data_xx, data_y, test_size=.5, random_state=42) # TODO\n",
        "\n",
        "svd = TruncatedSVD(n_components=20).fit(X_train) \n",
        "X_train_svd, X_test_svd = svd.transform(X_train), svd.transform(X_test)\n",
        "\n",
        "ss =StandardScaler()\n",
        "X_train_svd= ss.fit_transform(X_train_svd)\n",
        "X_test_svd = ss.transform(X_test_svd)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s55slIvZwlbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 308
        },
        "outputId": "e836ff23-ad9b-4bbb-e5d6-a9dc7d022c9f"
      },
      "source": [
        "#X_train.shape\n",
        "pd.DataFrame(X_train_svd).describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "      <td>7.425700e+04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>-5.931994e-17</td>\n",
              "      <td>-4.786255e-17</td>\n",
              "      <td>-9.060360e-19</td>\n",
              "      <td>2.713436e-18</td>\n",
              "      <td>3.659279e-18</td>\n",
              "      <td>5.977221e-17</td>\n",
              "      <td>7.995842e-17</td>\n",
              "      <td>-5.523652e-17</td>\n",
              "      <td>-4.996542e-17</td>\n",
              "      <td>2.681067e-17</td>\n",
              "      <td>-5.501440e-18</td>\n",
              "      <td>5.245066e-17</td>\n",
              "      <td>-5.625721e-17</td>\n",
              "      <td>-3.385618e-17</td>\n",
              "      <td>4.463073e-18</td>\n",
              "      <td>-3.644328e-19</td>\n",
              "      <td>1.506920e-17</td>\n",
              "      <td>-1.786307e-17</td>\n",
              "      <td>-8.147689e-18</td>\n",
              "      <td>1.012936e-17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "      <td>1.000007e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-1.326392e+00</td>\n",
              "      <td>-1.151137e+00</td>\n",
              "      <td>-2.413708e+00</td>\n",
              "      <td>-3.487665e+00</td>\n",
              "      <td>-2.104753e+00</td>\n",
              "      <td>-2.674641e+01</td>\n",
              "      <td>-8.434520e+00</td>\n",
              "      <td>-7.499560e+00</td>\n",
              "      <td>-8.542724e-01</td>\n",
              "      <td>-9.090700e+01</td>\n",
              "      <td>-2.041504e+01</td>\n",
              "      <td>-1.095229e+01</td>\n",
              "      <td>-1.408173e+01</td>\n",
              "      <td>-2.412788e+01</td>\n",
              "      <td>-3.065357e+01</td>\n",
              "      <td>-1.859074e+01</td>\n",
              "      <td>-7.435948e+00</td>\n",
              "      <td>-2.015774e+01</td>\n",
              "      <td>-2.596260e+01</td>\n",
              "      <td>-1.242226e+01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-8.755797e-01</td>\n",
              "      <td>-3.913524e-01</td>\n",
              "      <td>-5.128250e-01</td>\n",
              "      <td>-1.767810e-01</td>\n",
              "      <td>-9.207745e-02</td>\n",
              "      <td>-1.930832e-01</td>\n",
              "      <td>-2.264271e-01</td>\n",
              "      <td>-2.968542e-01</td>\n",
              "      <td>-7.007081e-02</td>\n",
              "      <td>-9.728091e-02</td>\n",
              "      <td>-4.405853e-02</td>\n",
              "      <td>-2.080524e-01</td>\n",
              "      <td>-1.489525e-01</td>\n",
              "      <td>-1.581456e-01</td>\n",
              "      <td>-1.245313e-01</td>\n",
              "      <td>-5.241785e-01</td>\n",
              "      <td>-6.029555e-01</td>\n",
              "      <td>-2.893544e-01</td>\n",
              "      <td>-5.997300e-02</td>\n",
              "      <td>-5.361539e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>-5.020869e-01</td>\n",
              "      <td>-1.233750e-01</td>\n",
              "      <td>3.230989e-02</td>\n",
              "      <td>6.118126e-02</td>\n",
              "      <td>-3.726680e-02</td>\n",
              "      <td>-1.047378e-01</td>\n",
              "      <td>2.602396e-01</td>\n",
              "      <td>4.433327e-03</td>\n",
              "      <td>-2.832086e-02</td>\n",
              "      <td>-3.282730e-02</td>\n",
              "      <td>2.256744e-02</td>\n",
              "      <td>2.599542e-02</td>\n",
              "      <td>-3.707194e-02</td>\n",
              "      <td>-5.999457e-02</td>\n",
              "      <td>-1.571433e-02</td>\n",
              "      <td>6.781884e-02</td>\n",
              "      <td>-2.921378e-02</td>\n",
              "      <td>3.065591e-03</td>\n",
              "      <td>-6.431958e-03</td>\n",
              "      <td>3.913307e-02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.204626e+00</td>\n",
              "      <td>1.852484e-02</td>\n",
              "      <td>2.398357e-01</td>\n",
              "      <td>1.710523e-01</td>\n",
              "      <td>2.798611e-02</td>\n",
              "      <td>4.613763e-02</td>\n",
              "      <td>6.220538e-01</td>\n",
              "      <td>3.710084e-01</td>\n",
              "      <td>7.139207e-02</td>\n",
              "      <td>3.499273e-02</td>\n",
              "      <td>1.300525e-01</td>\n",
              "      <td>2.306683e-01</td>\n",
              "      <td>1.217623e-01</td>\n",
              "      <td>9.623254e-02</td>\n",
              "      <td>6.444027e-02</td>\n",
              "      <td>4.085296e-01</td>\n",
              "      <td>1.346024e-01</td>\n",
              "      <td>3.824667e-01</td>\n",
              "      <td>5.212486e-02</td>\n",
              "      <td>4.492619e-01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>2.005726e+00</td>\n",
              "      <td>4.526969e+00</td>\n",
              "      <td>1.194687e+01</td>\n",
              "      <td>4.274254e+01</td>\n",
              "      <td>2.540734e+02</td>\n",
              "      <td>5.280319e+01</td>\n",
              "      <td>1.977229e+01</td>\n",
              "      <td>1.858820e+01</td>\n",
              "      <td>5.991677e+01</td>\n",
              "      <td>1.076784e+02</td>\n",
              "      <td>1.185268e+02</td>\n",
              "      <td>1.232672e+02</td>\n",
              "      <td>1.533263e+02</td>\n",
              "      <td>6.612642e+01</td>\n",
              "      <td>7.060549e+01</td>\n",
              "      <td>4.576437e+01</td>\n",
              "      <td>2.774570e+01</td>\n",
              "      <td>8.457870e+01</td>\n",
              "      <td>1.307231e+02</td>\n",
              "      <td>1.358720e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 0             1   ...            18            19\n",
              "count  7.425700e+04  7.425700e+04  ...  7.425700e+04  7.425700e+04\n",
              "mean  -5.931994e-17 -4.786255e-17  ... -8.147689e-18  1.012936e-17\n",
              "std    1.000007e+00  1.000007e+00  ...  1.000007e+00  1.000007e+00\n",
              "min   -1.326392e+00 -1.151137e+00  ... -2.596260e+01 -1.242226e+01\n",
              "25%   -8.755797e-01 -3.913524e-01  ... -5.997300e-02 -5.361539e-01\n",
              "50%   -5.020869e-01 -1.233750e-01  ... -6.431958e-03  3.913307e-02\n",
              "75%    1.204626e+00  1.852484e-02  ...  5.212486e-02  4.492619e-01\n",
              "max    2.005726e+00  4.526969e+00  ...  1.307231e+02  1.358720e+01\n",
              "\n",
              "[8 rows x 20 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGFhrkeeWW5Q"
      },
      "source": [
        "[source used](https://medium.com/@curiousily/credit-card-fraud-detection-using-autoencoders-in-keras-tensorflow-for-hackers-part-vii-20e0c85301bd)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qN5oyD7GUaFo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "043eadb3-dea6-4ee2-e091-b94536673848"
      },
      "source": [
        "input_dim = X_train_svd.shape[1]\n",
        "encoding_dim = 16\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "#encoder= BatchNormalization()(input_layer)\n",
        "encoder = Dense(encoding_dim, activation=\"tanh\", \n",
        "                activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
        "decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
        "decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "autoencoder = Model(inputs=input_layer, outputs=decoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehq048hauElU"
      },
      "source": [
        "# input_dim = X_train.shape[1]\n",
        "# encoding_dim = 14\n",
        "\n",
        "# input_layer = Input(shape=(input_dim, ))\n",
        "\n",
        "# encoder = Dense(encoding_dim, activation=\"tanh\", \n",
        "#                 activity_regularizer=regularizers.l1(10e-5))(input_layer)\n",
        "# encoder = Dense(int(encoding_dim / 2), activation=\"relu\")(encoder)\n",
        "\n",
        "# decoder = Dense(int(encoding_dim / 2), activation='tanh')(encoder)\n",
        "# decoder = Dense(input_dim, activation='relu')(decoder)\n",
        "\n",
        "# autoencoder = Model(inputs=input_layer, outputs=decoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZShEWRPkUaIv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "72c6e273-66e1-4766-e57f-153cb60ce0b2"
      },
      "source": [
        "nb_epoch = 150\n",
        "batch_size = 32\n",
        "autoencoder.compile(optimizer='adam', \n",
        "                    loss='mean_squared_error', # mean_squared_error\n",
        "                    metrics=['accuracy'])\n",
        "tensorboard = TensorBoard(histogram_freq=0,\n",
        "                          write_graph=True,\n",
        "                          write_images=True)\n",
        "\n",
        "# from keras.utils import plot_model\n",
        "# plot_model(autoencoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Re_4xlfNXq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b3df9aa4-f2d6-4a45-cb15-e610d4f3fd63"
      },
      "source": [
        "history = autoencoder.fit(X_train_svd, X_train_svd,\n",
        "                    epochs=nb_epoch,\n",
        "                    batch_size=batch_size,\n",
        "                    shuffle=True,\n",
        "                    validation_data=(X_test_svd, X_test_svd),\n",
        "                    verbose=1,\n",
        "                    callbacks=[tensorboard]).history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 74257 samples, validate on 74257 samples\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1122: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1125: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
            "\n",
            "Epoch 1/150\n",
            "74257/74257 [==============================] - 10s 133us/step - loss: 0.8359 - acc: 0.6224 - val_loss: 0.8649 - val_acc: 0.7898\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/callbacks.py:1265: The name tf.Summary is deprecated. Please use tf.compat.v1.Summary instead.\n",
            "\n",
            "Epoch 2/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.7598 - acc: 0.8207 - val_loss: 0.8271 - val_acc: 0.8317\n",
            "Epoch 3/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.7319 - acc: 0.8449 - val_loss: 0.7990 - val_acc: 0.8636\n",
            "Epoch 4/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.7097 - acc: 0.8763 - val_loss: 0.7803 - val_acc: 0.8718\n",
            "Epoch 5/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6983 - acc: 0.8818 - val_loss: 0.7663 - val_acc: 0.8892\n",
            "Epoch 6/150\n",
            "74257/74257 [==============================] - 9s 122us/step - loss: 0.6897 - acc: 0.8834 - val_loss: 0.7563 - val_acc: 0.8926\n",
            "Epoch 7/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6822 - acc: 0.8849 - val_loss: 0.7489 - val_acc: 0.8787\n",
            "Epoch 8/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6762 - acc: 0.8822 - val_loss: 0.7379 - val_acc: 0.8859\n",
            "Epoch 9/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6706 - acc: 0.8832 - val_loss: 0.7316 - val_acc: 0.8674\n",
            "Epoch 10/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6646 - acc: 0.8804 - val_loss: 0.7222 - val_acc: 0.8943\n",
            "Epoch 11/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6566 - acc: 0.8789 - val_loss: 0.7151 - val_acc: 0.8737\n",
            "Epoch 12/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6478 - acc: 0.8780 - val_loss: 0.6997 - val_acc: 0.8947\n",
            "Epoch 13/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6398 - acc: 0.8804 - val_loss: 0.6937 - val_acc: 0.8964\n",
            "Epoch 14/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6335 - acc: 0.8888 - val_loss: 0.6859 - val_acc: 0.9003\n",
            "Epoch 15/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6271 - acc: 0.8908 - val_loss: 0.6835 - val_acc: 0.9097\n",
            "Epoch 16/150\n",
            "74257/74257 [==============================] - 9s 122us/step - loss: 0.6215 - acc: 0.8950 - val_loss: 0.6762 - val_acc: 0.8924\n",
            "Epoch 17/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6173 - acc: 0.8967 - val_loss: 0.6714 - val_acc: 0.9050\n",
            "Epoch 18/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.6118 - acc: 0.8998 - val_loss: 0.6673 - val_acc: 0.9100\n",
            "Epoch 19/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.6092 - acc: 0.9000 - val_loss: 0.6649 - val_acc: 0.9128\n",
            "Epoch 20/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.6052 - acc: 0.9021 - val_loss: 0.6647 - val_acc: 0.8932\n",
            "Epoch 21/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.6029 - acc: 0.9015 - val_loss: 0.6596 - val_acc: 0.9112\n",
            "Epoch 22/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5995 - acc: 0.9033 - val_loss: 0.6548 - val_acc: 0.8967\n",
            "Epoch 23/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5960 - acc: 0.9012 - val_loss: 0.6538 - val_acc: 0.9048\n",
            "Epoch 24/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.5952 - acc: 0.9009 - val_loss: 0.6558 - val_acc: 0.8908\n",
            "Epoch 25/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5923 - acc: 0.8997 - val_loss: 0.6488 - val_acc: 0.9164\n",
            "Epoch 26/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5890 - acc: 0.8987 - val_loss: 0.6452 - val_acc: 0.9074\n",
            "Epoch 27/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5862 - acc: 0.8985 - val_loss: 0.6457 - val_acc: 0.9121\n",
            "Epoch 28/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5836 - acc: 0.9013 - val_loss: 0.6406 - val_acc: 0.9020\n",
            "Epoch 29/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5806 - acc: 0.8992 - val_loss: 0.6378 - val_acc: 0.9030\n",
            "Epoch 30/150\n",
            "74257/74257 [==============================] - 9s 126us/step - loss: 0.5780 - acc: 0.8997 - val_loss: 0.6360 - val_acc: 0.8987\n",
            "Epoch 31/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.5766 - acc: 0.8968 - val_loss: 0.6354 - val_acc: 0.8933\n",
            "Epoch 32/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.5762 - acc: 0.8983 - val_loss: 0.6339 - val_acc: 0.8999\n",
            "Epoch 33/150\n",
            "74257/74257 [==============================] - 9s 121us/step - loss: 0.5717 - acc: 0.8961 - val_loss: 0.6324 - val_acc: 0.8803\n",
            "Epoch 34/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.5706 - acc: 0.8976 - val_loss: 0.6299 - val_acc: 0.9012\n",
            "Epoch 35/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5681 - acc: 0.8965 - val_loss: 0.6238 - val_acc: 0.9057\n",
            "Epoch 36/150\n",
            "74257/74257 [==============================] - 8s 114us/step - loss: 0.5668 - acc: 0.8956 - val_loss: 0.6323 - val_acc: 0.9053\n",
            "Epoch 37/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5648 - acc: 0.8961 - val_loss: 0.6229 - val_acc: 0.8984\n",
            "Epoch 38/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5648 - acc: 0.8957 - val_loss: 0.6228 - val_acc: 0.8777\n",
            "Epoch 39/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.5598 - acc: 0.8999 - val_loss: 0.6172 - val_acc: 0.8980\n",
            "Epoch 40/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5590 - acc: 0.8955 - val_loss: 0.6183 - val_acc: 0.9058\n",
            "Epoch 41/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5596 - acc: 0.8913 - val_loss: 0.6142 - val_acc: 0.8966\n",
            "Epoch 42/150\n",
            "74257/74257 [==============================] - 9s 120us/step - loss: 0.5561 - acc: 0.8940 - val_loss: 0.6169 - val_acc: 0.8891\n",
            "Epoch 43/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5545 - acc: 0.8944 - val_loss: 0.6122 - val_acc: 0.9024\n",
            "Epoch 44/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5529 - acc: 0.8932 - val_loss: 0.6105 - val_acc: 0.9067\n",
            "Epoch 45/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5512 - acc: 0.8935 - val_loss: 0.6065 - val_acc: 0.9043\n",
            "Epoch 46/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5507 - acc: 0.8909 - val_loss: 0.6089 - val_acc: 0.9109\n",
            "Epoch 47/150\n",
            "74257/74257 [==============================] - 9s 115us/step - loss: 0.5524 - acc: 0.8935 - val_loss: 0.6064 - val_acc: 0.8888\n",
            "Epoch 48/150\n",
            "74257/74257 [==============================] - 9s 115us/step - loss: 0.5471 - acc: 0.8916 - val_loss: 0.6085 - val_acc: 0.8983\n",
            "Epoch 49/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5445 - acc: 0.8904 - val_loss: 0.6015 - val_acc: 0.8863\n",
            "Epoch 50/150\n",
            "74257/74257 [==============================] - 9s 115us/step - loss: 0.5441 - acc: 0.8903 - val_loss: 0.6015 - val_acc: 0.8748\n",
            "Epoch 51/150\n",
            "74257/74257 [==============================] - 9s 119us/step - loss: 0.5410 - acc: 0.8915 - val_loss: 0.5975 - val_acc: 0.8935\n",
            "Epoch 52/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5421 - acc: 0.8893 - val_loss: 0.6030 - val_acc: 0.8886\n",
            "Epoch 53/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5414 - acc: 0.8916 - val_loss: 0.5962 - val_acc: 0.8949\n",
            "Epoch 54/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5390 - acc: 0.8892 - val_loss: 0.5978 - val_acc: 0.9038\n",
            "Epoch 55/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5423 - acc: 0.8923 - val_loss: 0.5950 - val_acc: 0.8890\n",
            "Epoch 56/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5366 - acc: 0.8914 - val_loss: 0.6015 - val_acc: 0.8594\n",
            "Epoch 57/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5384 - acc: 0.8882 - val_loss: 0.5907 - val_acc: 0.9013\n",
            "Epoch 58/150\n",
            "74257/74257 [==============================] - 9s 116us/step - loss: 0.5350 - acc: 0.8899 - val_loss: 0.5961 - val_acc: 0.8928\n",
            "Epoch 59/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5345 - acc: 0.8877 - val_loss: 0.5919 - val_acc: 0.8984\n",
            "Epoch 60/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5317 - acc: 0.8904 - val_loss: 0.5901 - val_acc: 0.8846\n",
            "Epoch 61/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5338 - acc: 0.8902 - val_loss: 0.5843 - val_acc: 0.8679\n",
            "Epoch 62/150\n",
            "74257/74257 [==============================] - 9s 117us/step - loss: 0.5341 - acc: 0.8873 - val_loss: 0.5856 - val_acc: 0.8502\n",
            "Epoch 63/150\n",
            "74257/74257 [==============================] - 9s 118us/step - loss: 0.5300 - acc: 0.8897 - val_loss: 0.5859 - val_acc: 0.8980\n",
            "Epoch 64/150\n",
            "39392/74257 [==============>...............] - ETA: 2s - loss: 0.5422 - acc: 0.8895"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-342a6aee132b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_svd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test_svd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m                     callbacks=[tensorboard]).history\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    202\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2977\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2980\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2981\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2935\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2937\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2938\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyFQhg0iUaSJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "b74d013e-4f28-4385-b4ce-6842f6a63338"
      },
      "source": [
        "plt.plot(history['loss'])\n",
        "plt.plot(history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-dd675e12d727>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx1jRyWgUaVZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "outputId": "24256d46-ea8a-461f-f54d-2d71396f62e3"
      },
      "source": [
        "predictions = autoencoder.predict(X_test_svd)\n",
        "mse = np.mean(np.power(X_test_svd - predictions, 2), axis=1)\n",
        "error_df = pd.DataFrame({'reconstruction_error': mse,'true_class': y_test.values.reshape(1,-1)[0]})\n",
        "error_df.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reconstruction_error</th>\n",
              "      <th>true_class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>74257.000000</td>\n",
              "      <td>74257.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.585880</td>\n",
              "      <td>15.768951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>14.078053</td>\n",
              "      <td>4.521670</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.023231</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.090252</td>\n",
              "      <td>14.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.116053</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.268303</td>\n",
              "      <td>16.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1783.029915</td>\n",
              "      <td>39.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       reconstruction_error    true_class\n",
              "count          74257.000000  74257.000000\n",
              "mean               0.585880     15.768951\n",
              "std               14.078053      4.521670\n",
              "min                0.023231      0.000000\n",
              "25%                0.090252     14.000000\n",
              "50%                0.116053     16.000000\n",
              "75%                0.268303     16.000000\n",
              "max             1783.029915     39.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcAy5pgOv-dB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "818280fe-08e0-496a-9f1e-d51fdf0dda4d"
      },
      "source": [
        "autoencoder.evaluate(X_test_svd,X_test_svd)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "74257/74257 [==============================] - 2s 27us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.5894532675636395, 0.9032145117648062]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iS1yroRUaX2"
      },
      "source": [
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(111)\n",
        "# normal_error_df = error_df[(error_df['true_class']== 0) & (error_df['reconstruction_error'] < 10)]\n",
        "# _ = ax.hist(normal_error_df.reconstruction_error.values, bins=10)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EvCuHO55UaaS"
      },
      "source": [
        "# fig = plt.figure()\n",
        "# ax = fig.add_subplot(111)\n",
        "# fraud_error_df = error_df[error_df['true_class'] == 1]\n",
        "# _ = ax.hist(fraud_error_df.reconstruction_error.values, bins=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03slZw50UaRL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "8b86fbb6-7f0c-4a01-e8fb-021f52535f5c"
      },
      "source": [
        "fpr, tpr, thresholds = roc_curve(error_df.true_class, error_df.reconstruction_error,pos_label=2)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.plot(fpr, tpr, label='AUC = %0.4f'% roc_auc)\n",
        "plt.legend(loc='lower right')\n",
        "plt.plot([0,1],[0,1],'r--')\n",
        "plt.xlim([-0.001, 1])\n",
        "plt.ylim([0, 1.001])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niUJEROJSohARkbiUKEREJK7/BxHDojsn2jrhAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-pbYyAQWF9T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "54e104a8-616d-40c2-fa98-043a4be86ba1"
      },
      "source": [
        "precision, recall, th = precision_recall_curve(error_df.true_class, error_df.reconstruction_error,pos_label=2)\n",
        "plt.plot(recall, precision, 'b', label='Precision-Recall curve')\n",
        "plt.title('Recall vs Precision')\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f1d8e3fb320>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Recall vs Precision')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Recall')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Precision')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmfv/EuIgANeU0hAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rtw4oLWoWGAl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VYvOtK3WGDk"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZO3sHutWGGK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44ctGaksWGJq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcN0CkgdUaP-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAdJWAGfMBrW"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqMgvWslMBuT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dx6Hu-UDMBxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e57fac1a-af61-4001-9e49-6e5884489f10"
      },
      "source": [
        "import pandas as pd\n",
        "import pickle\n",
        "v1=3\n",
        "v2=4\n",
        "v3=5\n",
        "\n",
        "df1= pd.DataFrame({'v1': 3, 'v2': 4}, index=[0])\n",
        "print(df1)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   v1  v2\n",
            "0   3   4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bx9IfGB-ZyD7",
        "outputId": "a12a86d3-8ee6-4d0e-cca3-9a7157535a49"
      },
      "source": [
        "# Custom modules\n",
        "from data_prep import load_csv_data\n",
        "import model_abstraction as moda\n",
        "\n",
        "# Data Structures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Preprocessing or data manipulation methods\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Modeling methods and selection\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import OneClassSVM, LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
        "\n",
        "# Model assessment\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "def transform_labels(labels):\n",
        "    labels1 = []\n",
        "    for val in labels:\n",
        "        if val == 'anomaly':\n",
        "            labels1.append(1)\n",
        "        else:\n",
        "            labels1.append(0)\n",
        "    return labels1\n",
        "#X_train, y_train = load_csv_data('/content/UNSW_training_30_63.csv')\n",
        "data1 = pd.read_csv('/content/KDD_training_30_50.csv',header=0, index_col=0)\n",
        "\n",
        "features1 = data1.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "\n",
        "\n",
        "X_train=features1\n",
        "print('X_train', features1)\n",
        "print('X_train length', len(features1))\n",
        "\n",
        "y_train=data1.label\n",
        "print('y_train', y_train)\n",
        "print('y_train length', len(features1))\n",
        "\n",
        "\n",
        "y_train=transform_labels(y_train)\n",
        "\t\t\n",
        "data2 = pd.read_csv('/content/KDD_testing_30_10.csv',header=0, index_col=0)\n",
        "\n",
        "features2 = data2.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "X_test=features2\n",
        "y_test=data2.label\n",
        "\n",
        "y_test=transform_labels(y_test)\n",
        "\n",
        "\n",
        "gbc = GradientBoostingClassifier(random_state=42)\n",
        "gbc.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "print('X test length',len(X_test))\n",
        "print('y test length',len(y_test))\n",
        "\n",
        "y_pred=gbc.predict(X_test)\n",
        "print('y pred length',len(y_pred))\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy for Gradient Boost:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "lgr = LogisticRegression(solver = 'liblinear', penalty = 'l1', random_state=42)\n",
        "lgr.fit(X_train, y_train)\n",
        "y_pred=lgr.predict(X_test)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy for lgr:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier = KNeighborsClassifier(n_neighbors=10)\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred=classifier.predict(X_test)\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy for Knn:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "#Create a Gaussian Classifier\n",
        "model = GaussianNB()\n",
        "\n",
        "# Train the model using the training sets\n",
        "#model.fit(features,label)\n",
        "model.fit(X_train, y_train)\n",
        "y_pred=model.predict(X_test)\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy for Gaussian NB:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
        "dt = DecisionTreeClassifier()\n",
        "\n",
        "# Train Decision Tree Classifer\n",
        "dt.fit(X_train,y_train)\n",
        "y_pred=dt.predict(X_test)\n",
        "from sklearn import metrics\n",
        "# Model Accuracy, how often is the classifier correct?\n",
        "print(\"Accuracy for Decision Tree:\",metrics.accuracy_score(y_test, y_pred))\n",
        "\n",
        "\n"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train           src_bytes  dst_bytes  ...  dst_host_srv_serror_rate  dst_host_rerror_rate\n",
            "duration                        ...                                                \n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "0                 0          0  ...                      0.00                  0.95\n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "0                 0         15  ...                      0.00                  1.00\n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "...             ...        ...  ...                       ...                   ...\n",
            "0               145      13852  ...                      0.00                  0.00\n",
            "0               207       5200  ...                      0.00                  0.00\n",
            "0                35        130  ...                      0.00                  0.00\n",
            "0               383          0  ...                      0.01                  0.00\n",
            "0                45         81  ...                      0.00                  0.00\n",
            "\n",
            "[100048 rows x 36 columns]\n",
            "X_train length 100048\n",
            "y_train duration\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "      ...   \n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "Name: label, Length: 100048, dtype: object\n",
            "y_train length 100048\n",
            "X test length 25815\n",
            "y test length 25815\n",
            "y pred length 25815\n",
            "Accuracy for Gradient Boost: 0.9514235909355027\n",
            "Accuracy for lgr: 0.9024985473561883\n",
            "Accuracy for Knn: 0.9461553360449351\n",
            "Accuracy for Gaussian NB: 0.8921557234166182\n",
            "Accuracy for Decision Tree: 0.9546000387371684\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xRfhRHTDp3xz",
        "outputId": "7efa2c0d-56ec-49a2-da7c-d22a1d90560e"
      },
      "source": [
        "# Custom modules\n",
        "from data_prep import load_csv_data\n",
        "import model_abstraction as moda\n",
        "\n",
        "# Data Structures\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import roc_auc_score\n",
        "# Preprocessing or data manipulation methods\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# Modeling methods and selection\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.svm import OneClassSVM, LinearSVC\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split\n",
        "\n",
        "# Model assessment\n",
        "from sklearn.metrics import confusion_matrix, roc_auc_score\n",
        "\n",
        "# Visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "def show_auc(labels, t1, t2):\n",
        "    return roc_auc_score(labels, t1, multi_class='ovr'), roc_auc_score(labels, t2, multi_class='ovr')\n",
        "\n",
        "def transform_labels(labels):\n",
        "    labels1 = []\n",
        "    for val in labels:\n",
        "        if val == 'anomaly':\n",
        "            labels1.append(1)\n",
        "        else:\n",
        "            labels1.append(0)\n",
        "    return labels1\n",
        "#X_train, y_train = load_csv_data('/content/UNSW_training_30_63.csv')\n",
        "data1 = pd.read_csv('/content/KDD_training_30_50.csv',header=0, index_col=0)\n",
        "\n",
        "features1 = data1.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "\n",
        "\n",
        "X_train=features1\n",
        "print('X_train', features1)\n",
        "print('X_train length', len(features1))\n",
        "\n",
        "y_train=data1.label\n",
        "print('y_train', y_train)\n",
        "print('y_train length', len(features1))\n",
        "\n",
        "\n",
        "y_train=transform_labels(y_train)\n",
        "\n",
        "\n",
        "clf1 = IsolationForest(random_state=0).fit(X_train)\n",
        "clf2 = OneClassSVM(gamma='auto').fit(X_train)\n",
        "\n",
        "#data2 = pd.read_csv('/content/KDD_testing_30_50.csv',header=0, index_col=0)\n",
        "\n",
        "#features2 = data2.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "#X_test=features2\n",
        "#y_test=data2.label\n",
        "\n",
        "#y_test=transform_labels(y_test)\n",
        "\n",
        "\n",
        "# Test data\n",
        "data2 = pd.read_csv('/content/KDD_testing_30_50.csv',header=0, index_col=0)\n",
        "\n",
        "Y=data2.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "print(\"Y\", Y)\n",
        "print(\"y length\", len(Y))\n",
        "#Y = Y.replace([np.inf, -np.inf], np.nan)\n",
        "# Drop all occurences of NaN\n",
        "#Y = Y.dropna()\n",
        "# Double check these are all gone\n",
        "#print(\"CHecking Y\",Y.isnull().any().any())\n",
        "Y = Y.to_numpy()\n",
        "#labels = list(Y1[:, -1])\n",
        "#labels = transform_labels(labels)\n",
        "labels=transform_labels(data2.label)\n",
        "#labels[0] = -1\n",
        "#print (labels)\n",
        "#Y = pd.read_csv('/content/KDD_testing_30_50.csv')\n",
        "#Y=Y.select_dtypes(exclude='object').iloc[:,:-1]\n",
        "\n",
        "#Y = Y[:, :-1]\n",
        "\n",
        "\n",
        "#Y[Y == 'anomaly'] = 1\n",
        "#print ('Test shape. ', np.shape(Y))\n",
        "\n",
        "t1, t2 = [], []\n",
        "\n",
        "#t1 = []\n",
        "for i in range(np.shape(Y)[0]):\n",
        "    test_data = [float(val) for val in Y[i, :]]\n",
        "    # print (test_data)\n",
        "    #print ('Data point ', str(i))\n",
        "\n",
        "    t1.append(clf1.predict([test_data])[0])\n",
        "    t2.append(clf2.predict([test_data])[0])\n",
        "\n",
        "#print (t1, t2)\n",
        "#print (t1)\n",
        "print (show_auc(labels, t1,t2))\n"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train           src_bytes  dst_bytes  ...  dst_host_srv_serror_rate  dst_host_rerror_rate\n",
            "duration                        ...                                                \n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "0                 0          0  ...                      0.00                  0.95\n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "0                 0         15  ...                      0.00                  1.00\n",
            "0                 0          0  ...                      1.00                  0.00\n",
            "...             ...        ...  ...                       ...                   ...\n",
            "0               145      13852  ...                      0.00                  0.00\n",
            "0               207       5200  ...                      0.00                  0.00\n",
            "0                35        130  ...                      0.00                  0.00\n",
            "0               383          0  ...                      0.01                  0.00\n",
            "0                45         81  ...                      0.00                  0.00\n",
            "\n",
            "[100048 rows x 36 columns]\n",
            "X_train length 100048\n",
            "y_train duration\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "0    anomaly\n",
            "      ...   \n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "0     normal\n",
            "Name: label, Length: 100048, dtype: object\n",
            "y_train length 100048\n",
            "Y           src_bytes  dst_bytes  ...  dst_host_srv_serror_rate  dst_host_rerror_rate\n",
            "duration                        ...                                                \n",
            "0                 0          0  ...                      0.00                  1.00\n",
            "0                20          0  ...                      0.00                  0.00\n",
            "1                 0         15  ...                      0.00                  0.83\n",
            "0               129        174  ...                      0.01                  0.02\n",
            "0                26        157  ...                      0.00                  0.00\n",
            "...             ...        ...  ...                       ...                   ...\n",
            "0               207        294  ...                      0.00                  0.00\n",
            "0                45         76  ...                      0.00                  0.00\n",
            "0                 0          0  ...                      0.00                  0.37\n",
            "0               322       2073  ...                      0.00                  0.00\n",
            "0                46        129  ...                      0.00                  0.00\n",
            "\n",
            "[42876 rows x 36 columns]\n",
            "y length 42876\n",
            "(0.4145442671891034, 0.7379186491277171)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v2sP_bFyp4d-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        },
        "id": "ECeF1aYvmS8c",
        "outputId": "f1cee548-8b63-4f6c-c30c-fd434f5e5969"
      },
      "source": [
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.svm import OneClassSVM\n",
        "from sklearn.metrics import roc_auc_score\n",
        "X = pd.read_csv('/content/KDD_training_30_50.csv')\n",
        "# Replace Inf values with NaN\n",
        "#X = X.replace([np.inf, -np.inf], np.nan)\n",
        "# Drop all occurences of NaN\n",
        "#X = X.dropna()\n",
        "# Double check these are all gone\n",
        "#print(\"Checking X\",X.isnull().any().any())\n",
        "#X=X.dropna(inplace=True)\n",
        "def transform_labels(labels):\n",
        "    labels1 = []\n",
        "    for val in labels:\n",
        "        if val == 'anomaly':\n",
        "            labels1.append(1)\n",
        "        else:\n",
        "            labels1.append(0)\n",
        "    return labels1\n",
        "y_train=X.label\n",
        "y_train=transform_labels(y_train)\n",
        "\n",
        "#features = list(X.keys())[:-1]\n",
        "# print (len(features))\n",
        "\n",
        "X = X.to_numpy()\n",
        "X = X[:, :-1]\n",
        "\n",
        "# print (X)\n",
        "# print (np.shape(X))\n",
        "\n",
        "\n",
        "clf1 = IsolationForest(random_state=0).fit(X)\n",
        "#clf2 = OneClassSVM(gamma='auto').fit(X)\n",
        "\n",
        "# Test data\n",
        "Y = pd.read_csv('/content/KDD_training_30_50.csv')\n",
        "#Y = Y.replace([np.inf, -np.inf], np.nan)\n",
        "# Drop all occurences of NaN\n",
        "#Y = Y.dropna()\n",
        "# Double check these are all gone\n",
        "#print(\"CHecking Y\",Y.isnull().any().any())\n",
        "Y = Y.to_numpy()\n",
        "labels = list(Y[:, -1])\n",
        "labels = transform_labels(labels)\n",
        "#labels[0] = -1\n",
        "#print (labels)\n",
        "\n",
        "Y = Y[:, :-1]\n",
        "\n",
        "\n",
        "Y[Y == 'anomaly'] = 1\n",
        "#print ('Test shape. ', np.shape(Y))\n",
        "\n",
        "#t1, t2 = [], []\n",
        "\n",
        "t1 = []\n",
        "for i in range(np.shape(Y)[0]):\n",
        "    test_data = [float(val) for val in Y[i, :]]\n",
        "    # print (test_data)\n",
        "    print ('Data point ', str(i))\n",
        "\n",
        "    t1.append(clf1.predict([test_data])[0])\n",
        "    #t2.append(clf2.predict([test_data])[0])\n",
        "\n",
        "#print (t1, t2)\n",
        "print (t1)\n",
        "print (show_auc(labels, t1))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-2c4ff9936bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mclf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIsolationForest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;31m#clf2 = OneClassSVM(gamma='auto').fit(X)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_iforest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    254\u001b[0m                 )\n\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'csc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m             \u001b[0;31m# Pre-sort indices to avoid that each individual tree of the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    529\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"unsafe\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'tcp'"
          ]
        }
      ]
    }
  ]
}